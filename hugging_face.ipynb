{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2a4edb",
   "metadata": {},
   "source": [
    "1.加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6c5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 指定本地文件路径\n",
    "dataset = load_dataset('parquet', data_files={\n",
    "    'train': 'C:/Users/10520/Desktop/huggingface_dataset/yelp_review_full/train-00000-of-00001.parquet',\n",
    "    'test': 'C:/Users/10520/Desktop/huggingface_dataset/yelp_review_full/test-00000-of-00001.parquet'\n",
    "})\n",
    "\n",
    "dataset2 = load_dataset('json', data_files={\n",
    "    'train': 'C:/Users/10520/Desktop/huggingface_dataset/sst5/train.jsonl',\n",
    "    'test': 'C:/Users/10520/Desktop/huggingface_dataset/sst5/test.jsonl'\n",
    "})\n",
    "\n",
    "\n",
    "# 访问训练集中的第100条数据\n",
    "# print(dataset['train'][100])\n",
    "\n",
    "# 查看训练集和测试集的条目数量\n",
    "train_size = len(dataset['train'])\n",
    "test_size = len(dataset['test'])\n",
    "\n",
    "print(\"训练集条目数量:\", train_size)\n",
    "print(\"测试集条目数量:\", test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21033990",
   "metadata": {},
   "source": [
    "2.数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecf5e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from pprint import pprint\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"C:/Users/10520/Desktop/huggingface_model/distilbert\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets2 = dataset2.map(tokenize_function, batched=True)\n",
    "\n",
    "print(tokenized_datasets[\"train\"][0]) # 查看训练集的前五条数据\n",
    "# print(tokenized_datasets[\"test\"][:5])  # 查看训练集的前五条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(30000))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(20000))\n",
    "\n",
    "input_ids = np.array(small_train_dataset[\"input_ids\"])\n",
    "attention_mask = np.array(small_train_dataset[\"attention_mask\"])\n",
    "labels = np.array(small_train_dataset[\"label\"])\n",
    "\n",
    "x = [input_ids, attention_mask]\n",
    "y = labels  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0797d20",
   "metadata": {},
   "source": [
    "3.自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class CustomTFEmbeddings(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom embeddings layer to concatenate input embeddings and position embeddings.\"\"\"\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.config = config\n",
    "        self.dim = config.dim\n",
    "        self.initializer_range = config.initializer_range\n",
    "        self.max_position_embeddings = config.max_position_embeddings\n",
    "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=1e-12, name=\"LayerNorm\")\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=config.dropout)\n",
    "        \n",
    "        # 添加线性层\n",
    "        self.linear_layer = tf.keras.layers.Dense(self.config.hidden_size, activation='relu')\n",
    "\n",
    "    def build(self, input_shape=None):\n",
    "        self.weight = self.add_weight(\n",
    "            name=\"weight\",\n",
    "            shape=[self.config.vocab_size, self.dim],\n",
    "            initializer=tf.keras.initializers.TruncatedNormal(stddev=self.initializer_range),\n",
    "        )\n",
    "        self.position_embeddings = self.add_weight(\n",
    "            name=\"embeddings\",\n",
    "            shape=[self.max_position_embeddings, self.dim],\n",
    "            initializer=tf.keras.initializers.TruncatedNormal(stddev=self.initializer_range),\n",
    "        )\n",
    "\n",
    "    def call(self, input_ids=None, position_ids=None, inputs_embeds=None, training=False):\n",
    "        assert not (input_ids is None and inputs_embeds is None)\n",
    "\n",
    "        if input_ids is not None:\n",
    "            inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\n",
    "\n",
    "        input_shape = tf.shape(inputs_embeds)[:-1]\n",
    "\n",
    "        if position_ids is None:\n",
    "            position_ids = tf.expand_dims(tf.range(start=0, limit=input_shape[-1]), axis=0)\n",
    "\n",
    "        position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)\n",
    "\n",
    "        # 使用串联操作\n",
    "        final_embeddings = tf.concat([inputs_embeds, position_embeds], axis=-1)\n",
    "\n",
    "        final_embeddings = self.LayerNorm(final_embeddings)\n",
    "        final_embeddings = self.dropout(final_embeddings, training=training)\n",
    "\n",
    "        # 添加线性层\n",
    "        final_embeddings = self.linear_layer(final_embeddings)\n",
    "\n",
    "        return final_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15860f64",
   "metadata": {},
   "source": [
    "将前馈网络中的两个线性层中间增加卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_tf_utils import get_initializer\n",
    "from transformers.activations_tf import get_tf_activation\n",
    "\n",
    "class CustomTFFFN(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "        \n",
    "        # 第一个线性层\n",
    "        self.lin1 = tf.keras.layers.Dense(\n",
    "            config.hidden_dim, kernel_initializer=get_initializer(config.initializer_range), name=\"lin1\"\n",
    "        )\n",
    "        \n",
    "        # 添加卷积层\n",
    "        self.conv1d = tf.keras.layers.Conv1D(\n",
    "            filters=config.hidden_dim,  # 卷积核的个数应该匹配输入的维度\n",
    "            kernel_size=3,  # 卷积核的大小，你可以根据需求调整\n",
    "            padding='same',  # 保持输入和输出的长度相同\n",
    "            activation='relu',  # 激活函数\n",
    "            name=\"conv1d\"\n",
    "        )\n",
    "        \n",
    "        # 第二个线性层\n",
    "        self.lin2 = tf.keras.layers.Dense(\n",
    "            config.dim, kernel_initializer=get_initializer(config.initializer_range), name=\"lin2\"\n",
    "        )\n",
    "        \n",
    "        self.activation = get_tf_activation(config.activation)\n",
    "        self.config = config\n",
    "\n",
    "    def call(self, input, training=False):\n",
    "        # 线性层1\n",
    "        x = self.lin1(input)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # 添加卷积层\n",
    "        x = self.conv1d(x)\n",
    "        \n",
    "        # 线性层2\n",
    "        x = self.lin2(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        return x\n",
    "\n",
    "    def build(self, input_shape=None):\n",
    "        if self.built:\n",
    "            return\n",
    "        self.built = True\n",
    "        if getattr(self, \"lin1\", None) is not None:\n",
    "            with tf.name_scope(self.lin1.name):\n",
    "                self.lin1.build([None, None, self.config.dim])\n",
    "        if getattr(self, \"lin2\", None) is not None:\n",
    "            with tf.name_scope(self.lin2.name):\n",
    "                self.lin2.build([None, None, self.config.hidden_dim])\n",
    "        if getattr(self, \"conv1d\", None) is not None:\n",
    "            with tf.name_scope(self.conv1d.name):\n",
    "                self.conv1d.build([None, None, self.config.hidden_dim])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c1778c",
   "metadata": {},
   "source": [
    "修改模型中的对应类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb47cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.distilbert import modeling_tf_distilbert\n",
    "\n",
    "\n",
    "modeling_tf_distilbert.TFEmbeddings = CustomTFEmbeddings\n",
    "\n",
    "modeling_tf_distilbert.TFFFN = CustomTFFFN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac1442",
   "metadata": {},
   "source": [
    "5.加载模型，训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98415f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification,TFDistilBertForSequenceClassification,AutoConfig\n",
    "\n",
    "# 创建 TensorFlow 数据集\n",
    "test_tf_dataset = small_test_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask'],\n",
    "    label_cols='label',\n",
    "    shuffle=True,\n",
    "    batch_size = 32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fc66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 加载模型\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\"C:/Users/10520/Desktop/huggingface_model/distilbert\", num_labels=5, ignore_mismatched_sizes=True)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer=Adam(learning_rate=2e-5), \n",
    "              metrics=['accuracy'],\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "# 设置早停策略\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',   # 监测的指标\n",
    "    patience=3,           # 容忍的epoch数，即验证集损失没有改善的连续epoch数\n",
    "    restore_best_weights=True  # 恢复训练过程中验证集损失最小的模型权重\n",
    ")\n",
    "# 创建 ReduceLROnPlateau 调度器\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    x,y,\n",
    "    validation_split = 0.1,\n",
    "    epochs=25, \n",
    "    batch_size=8, \n",
    "    callbacks=[early_stopping,reduce_lr]  # 添加早停回调\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f86389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.title('loss curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 绘制准确率曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='training accuray')\n",
    "plt.plot(history.history['val_loss'], label='validation accuracy')\n",
    "plt.title('loss curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee46494",
   "metadata": {},
   "source": [
    "评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfd167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型\n",
    "results = model.evaluate(test_tf_dataset)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"C:/Users/10520/Desktop/huggingface_model/distilbert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
